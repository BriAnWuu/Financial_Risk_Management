---
title: Financial Risk Management
author: BRIAN WU
output:
  html_document:
    theme: united
    toc: true
    toc_float: true
    df_print: paged
---

```{r include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE) # Suppress warning and message
```

## **Introduction**
This project aims to provide a comprehensive analysis of the quantitative risks inherent in a portfolio of options on the S&P 500 index. Leveraging the versatile capabilities of the R programming language, we perform a series of tasks to quantify and mitigate risks associated with the portfolio.

**Project Objectives:</strong>**

1. **Calculation of Greek Letter Risks:** We begin by calculating the Greek letter risks of the portfolio, including delta, gamma, theta, vega, and rho. These measures provide insights into the portfolio's sensitivity to changes in underlying factors such as stock price, volatility, time decay, and interest rates.

2. **Visualization of Portfolio Value:** We visualize the portfolio's value as the index value of the S&P 500 changes, allowing for a dynamic understanding of how market movements impact the portfolio's performance.

3. **Modeling Market Volatility:** Utilizing **GARCH** (Generalized Autoregressive Conditional Heteroskedasticity) and **DCC** (Dynamic Conditional Correlation) models, we analyze and model the changes in the S&P 500 index and the VIX index. These models help capture the time-varying volatility and correlation dynamics of the market.

4. **Delta-Normal Value at Risk (VaR) Calculation:** We calculate the delta-normal VaR, a widely used risk measure that estimates the maximum potential loss of the portfolio at a specified confidence level over a given time horizon, assuming normal market conditions.

5. **Filtered Historical Simulation VaR (1-Day Holding Period):** Employing filtered historical simulation, we estimate the VaR of the portfolio for a one-day holding period. This approach incorporates real market data and accounts for the impact of historical events on portfolio performance.

6. **Filtered Historical Simulation VaR (1-Month Holding Period):** Extending the analysis, we calculate the filtered historical simulation VaR for a one-month holding period, providing insights into the longer-term risk exposure of the portfolio.

See more details at my [github repository](https://github.com/BriAnWuu/Financial_Risk_Management).

### Install Packages
All R packages below are on [CRAN](https://cran.r-project.org/), and can be installed with `install.packages` on any R Console.
```{r}
library(xts) # Time series data in finance
library(rmgarch) # ARMA, GARCH, and DCC models
library(fOptions) # Option valuation
library(openxlsx) # Spreadsheet reading
library(tidyverse) # Data Science package
library(lubridate) # Makes it easier to deal with dates and times
library(SciViews) # R workflow
library(ggplot2) # Data visualization
library(scales) # Override ggplot2 graphs
options(scipen = 999) # Avoid scientific notation throughout document
```

## **Portfolio Overview**

```{r include=FALSE}
optionData <- read.xlsx("data/optiondata.xlsx", rows = c(5:25), detectDates = TRUE, sheet = "Option prices")
yieldCurve <- read.xlsx("data/optiondata.xlsx", sheet = "zero-coupon yield curve")

# Get SPX info
currentInfo <- read.xlsx("data/optiondata.xlsx", rows = c(1:3), cols = c(1:2), colNames = FALSE, sheet = "Option prices")

DATE <- as.Date(currentInfo[1, 2], origin = "1899-12-30") # Evaluation date 2020/10/30
SPOT <- currentInfo[2, 2] # Spot price of SPX on evaluation date
q <- currentInfo[3, 2] # Dividend yield of SPX
```

### Portfolio

```{r}
# Portfolio consists of 20 options
optionData
```

### Yield Curve
```{r}
yieldCurve
```

### Important Information 
Parameters that will be used throughout this Project
```{r}
DATE # Evaluation date 2020/10/30
SPOT # Spot price of SPX on evaluation date
q # Dividend yield of SPX
```


## **Greek Letter Risks of Portfolio**

### Time to Expiry
Calculate the time to expiry for each option position in the portfolio.
```{r}
n <- nrow(optionData) # Number of option positions

# Calculate time to expiry in terms of days

# If the Expiration.Time column Open and we need to minus 6.5/24 
# If the Expiration.Time column Close and we do not need to minus 6.5/24 

time_to_expiry_days <- rep(0, n)

for (i in 1:n) {
  t <- optionData$Expiration.Time[i]
  d <- optionData$Expiration.Date[i]
  
  if (t == "Open") {
    time_to_expiry_days[i] <- d - DATE - (6.5/24)
  } else {
    time_to_expiry_days[i] <- d - DATE
  }
}

# Add time_to_expiry to optionData
optionData$time_to_expiry_days <- time_to_expiry_days

# Calculate time to expiry in terms of years
optionData$time_to_expiry_years <- time_to_expiry_days / 365 

# Print
optionData$time_to_expiry_days
```

### Interest Rates 
Linear Interpolation of interest rate:  
$$R_{n} = R_{1} + \frac{R_{2} - R_{1}}{t_{2} - t_{1}} * (t_{n} - t_{1})$$  
where:
\begin{align*}
& R_{n} = \text{unknown rate}  \\
& R_{1} = \text{rate for the shorter designated maturity (nearest to the reset date)}  \\
& R_{2} = \text{rate for the longer designated maturity (nearest to the reset date)}  \\
& t_{n} = \text{number of calendar days to expiry of option}  \\
& t_{1} = \text{number of calendar days to the shorter designated maturity}  \\
& t_{2} = \text{number of calendar days to the longer designated maturity}  
\end{align*}
```{r}
rates <- rep(0, n)

# Rates for each position
for (i in 1:n) {
  tn <- optionData$time_to_expiry_days[i]
  
  # Search through yield curve to find appropriate parameters
  for (j in 1:nrow(yieldCurve)) {
    if (yieldCurve$days[j] >= tn) {
      t1 <- yieldCurve$days[j - 1]
      t2 <- yieldCurve$days[j]
      r1 <- yieldCurve$rate[j - 1]
      r2 <- yieldCurve$rate[j]
      break
    }
  }
  
  # Linear interpolation
  rates[i] <- r1 + (r2 - r1) * (tn - t1) / (t2 - t1)
}

# Add rates to optionData
optionData$Rate <- rates / 100 # rates in %
optionData$Rate
```

### Implied Volatility
```{r}
vol <- rep(0, n)

for (i in 1:n) {
  vol[i] <- GBSVolatility(price = optionData[i, "Price"], TypeFlag = "c", S = SPOT, X = optionData[i, "Strike.Price"], Time = optionData[i, "time_to_expiry_years"], r = optionData[i, "Rate"], b = optionData[i, "Rate"] - q)
}

optionData$Implied.volatility <- vol
optionData$Implied.volatility
```

### Compute d1 and d2
Price of call option C is given as the following formula:
$$C = Se^{-qt}N(d_{1}) - Ke^{-rt}N(d_{2})$$
where:
$$d_{1} = \frac{\ln(\frac{S}{K}) + (r - q + \frac{\sigma^{2}}{2})*t}{\sigma\sqrt{t}}$$
$$d_{2} = d_{1} - \sigma\sqrt{t}$$
where:
\begin{align*}
& S = \text{Spot price of underlying asset}  \\
& K = \text{Strike price}  \\
& r = \text{Interest rate}  \\
& q = \text{Dividend yield of underlying asset}  \\
& \sigma = \text{Volatility}  \\
& t = \text{Time to maturity}  \\
& N() = \text{Normal distribution}  
\end{align*}
```{r}
# Utilize R vectorization to make calculations cleaner
X <- optionData$Strike.Price
r <- optionData$Rate
sig <- optionData$Implied.volatility
t <- optionData$time_to_expiry_years

optionData$d1 <- ((ln(SPOT/X) + (r - q + 0.5 * sig ^ 2) * t)) / (sig * sqrt(t))
optionData$d2 <- optionData$d1 - sig * sqrt(t)
```

### Greeks
**Delta** $\Delta$:

* Delta measures the sensitivity of an option's price to changes in the price of the underlying asset.
* $\Delta_{c} = \frac{\partial C}{\partial S} = e^{-qt} N(d_{1})$

**Gamma** $\Gamma$:

* Gamma measures the rate of change of Delta with respect to changes in the price of the underlying asset.
* $\Gamma_{c} = \frac{\partial^2 C}{\partial S^2} = e^{-qt} * \frac{N'(d_{1})}{S\sigma\sqrt{t}}$

**Theta** $\Theta$:

* Theta measures the rate of change of an option's price with respect to the passage of time. (Theta equation below is annualized, divide by 365 or 252 to get per-calendar-day or per-trading-day theta)
* $\Theta_{c} = \frac{\partial C}{\partial t} = -e^{-qt}\frac{S\sigma}{2\sqrt{t}} N'(d_{1}) - rKe^{-rt}N(d_{2}) + qSe^{-qt}N(d_{1})$

**Vega** $\nu$:

* Vega measures the sensitivity of an option's price to changes in volatility.
* $\nu_{c} = \frac{\partial C}{\partial \sigma} = Se^{-qt}\sqrt{t}N'(d_{1})$

**Rho** $\rho$:

* Rho measures the sensitivity of an option's price to changes in interest rates.
* $\rho_{c} = \frac{\partial C}{\partial r} = Kte^{-rt}N(d_{2})$

```{r}
X <- optionData$Strike.Price
Multiplier <- optionData$Multiplier
t <- optionData$time_to_expiry_years
r <- optionData$Rate
sig <- optionData$Implied.volatility
d1 <- optionData$d1
d2 <- optionData$d2

optionData$Delta <- Multiplier * exp(-q * t) * pnorm(d1)
optionData$Gamma <- Multiplier * exp(-q * t) * dnorm(d1) / (SPOT * sig * sqrt(t))
optionData$Theta <- Multiplier * {-0.5 * SPOT * sig * exp(-q * t) * dnorm(d1) / sqrt(t) - r * X * exp(-r * t) * pnorm(d2) + q * SPOT * exp(-q * t) * pnorm(d1)}
optionData$Vega  <- Multiplier * SPOT * exp(-q * t) * sqrt(t) * dnorm(d1)
optionData$Rho <- Multiplier * X * t * exp(-r * t) * pnorm(d2)

# Print data frame
optionData[, c("Strike.Price", "Quantity", "Implied.volatility", "Delta", "Gamma", "Theta", "Vega", "Rho")]
```

### Portfolio Greeks
```{r}
portfolioGreeks <- data.frame(row.names = "Portfolio",
                              Delta = sum(optionData$Delta * optionData$Quantity),
                              Gamma = sum(optionData$Gamma * optionData$Quantity),
                              Theta = sum(optionData$Theta * optionData$Quantity),
                              Vega = sum(optionData$Vega * optionData$Quantity),
                              Rho = sum(optionData$Rho * optionData$Quantity))
format(portfolioGreeks, big.mark = ",")
```

### Portfolio value as SPX value changes
```{r}
# Parameters
X <- optionData$Strike.Price
Quantity <- optionData$Quantity
Multiplier <- optionData$Multiplier
sig <- optionData$Implied.volatility
t <- optionData$time_to_expiry_years
r <- optionData$Rate

# Calculate portfolio value for SPX values ranging from -20% to +20% of spot price
value <- c()
for (s in as.integer(0.8 * SPOT):as.integer(1.2 * SPOT)) {
  
  # Calculate value for each option position as spot price changes
  # Since parameters are all vectorized, value_part will also be a vector
  value_part <- Multiplier * Quantity * GBSOption(TypeFlag = "c", S = s, X = X, Time = t, r = r, b = r - q, sigma = sig)@price
  
  # Append portfolio value
  value <- c(value, sum(value_part))
}
```

### Data Visualization
```{r echo=FALSE}
priceChange <- data.frame(SPX = seq(-20, 20, 40 / (as.integer(1.2 * SPOT) - as.integer(0.8 * SPOT))), 
                          Value = value)

priceChange %>% 
  ggplot(aes(x=SPX, y=Value/1000000)) +
  geom_line() +
  ggtitle("Portfolio value as a function of % change in stock index") +
  xlab("% change in stock index") +
  ylab("Portfolio value (million $)") +
  scale_y_continuous(labels = comma)
```

## **Indices Overview**

### Load Data
```{r}
# Load data
SPX_history <- read.csv("data/SPX_History.csv")
VIX_history <- read.csv("data/VIX_History.csv")

SPX <- subset(SPX_history, select = c(Date,Close))
VIX <- subset(VIX_history, select = c(Date,Close))
SPX$Date <- as.Date(SPX$Date, format="%m/%d/%Y")
VIX$Date <- as.Date(VIX$Date, format="%m/%d/%Y")

# Merge dataframes
colnames(SPX)[colnames(SPX) == "Close"] <- "SPX"
colnames(VIX)[colnames(VIX) == "Close"] <- "VIX"
indexData <- merge(SPX, VIX, by = "Date")
indexData
```

### SPX Index
```{r echo=FALSE, out.width="100%"}
SPX %>%
  ggplot(aes(x=Date, y=SPX)) +
  geom_line() +
  ggtitle("Historical SPX Index Value") +
  xlab("Date") +
  ylab("SPX Value") +
  scale_y_continuous(labels = comma)
```

### VIX Index
```{r echo=FALSE, out.width="100%"}
VIX %>%
  ggplot(aes(x=Date, y=VIX)) +
  geom_line() +
  ggtitle("Historical VIX Index Value") +
  xlab("Date") +
  ylab("VIX Value") +
  scale_y_continuous(labels = comma)
```


## **Modeling SPX and VIX Index**

### Compute Index Log Return
Log Returns can be define as:
$$z_{t} = ln(\frac{p_{t}}{p_{t-1}}) = ln(1+r_{t})$$
where:
\begin{align*}
& p_{t} = \text{Price of an asset at time t}  \\
& p_{t-1} = \text{Price of an asset at time t-1}  \\
& r_{t} = \text{Rate of return at time t}
\end{align*}

Some nice properties of Logarithmic Returns:

1. **Normality:** Log returns often exhibit a more symmetric and approximately normal distribution, especially for assets with high liquidity. This assumption of normality simplifies statistical analysis and allows for the application of various mathematical models and techniques that rely on normality assumptions.

2. **Additivity:** Logarithms have the property of additivity, which means that log returns can be summed **over time periods**. This property simplifies the calculation of **cumulative returns** and makes it easier to analyze the overall performance of an investment over multiple periods.

3. **Mathematical Convenience**: Logarithmic transformation simplifies mathematical calculations, particularly when dealing with multiplicative processes or **compounding returns**. It can also be converted to simple returns easily.

4. **Stationarity:** Log returns tend to be **more stationary** compared to simple returns. Stationarity implies that statistical properties such as mean, variance, and autocorrelation remain constant over time. Modeling stationary series simplifies the analysis and interpretation of financial data.

5. **Interpretability:** Log returns are interpretable as **continuously compounded returns**, which represent the geometric mean rate of return over a given period. 

6. **Empirical Evidence:** Empirical studies have shown that log returns often provide better models for asset price movements compared to simple returns. They capture the essence of financial markets more accurately and are widely used in empirical finance research.

```{r}
n_idx <- nrow(indexData)
indexData$SPX.Return[2:n_idx] <- log(indexData$SPX[2:n_idx] / indexData$SPX[1:(n_idx - 1)])
indexData$VIX.Return[2:n_idx] <- log(indexData$VIX[2:n_idx] / indexData$VIX[1:(n_idx - 1)])

# Get the most recent 1000 observations
idx_DATE <- which(indexData$Date == DATE)
returns <- indexData[(idx_DATE - 999):idx_DATE, c("Date", "SPX.Return", "VIX.Return")]
returns
```

### Model Log Returns using ARMA and GARCH
{equation}
```{r}
# Univariate GARCH specification prior to fitting
# Estimation of the parameters
spec1 <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1,1)),
                    mean.model = list(armaOrder = c(0,0), include.mean = FALSE),
                    distribution.model = "norm")

spec2 <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1,1)),
                    mean.model = list(armaOrder = c(1,0), include.mean = TRUE),
                    distribution.model = "norm")

# Fitting GARCH model
fitSPX <- ugarchfit(spec = spec1, data = returns$SPX.Return)
fitVIX <- ugarchfit(spec = spec2, data = returns$VIX.Return)

# GARCH coefficients
coef(fitSPX)
coef(fitVIX)
```

### Estimation of the DCC model
{equation}
```{r}
multiSpec <- multispec(c(spec1, spec2))
dccSpec <- dccspec(multiSpec, dccOrder = c(1,1), model = "DCC", distribution = "mvnorm")
fitDcc <- dccfit(dccSpec,returns[, c("SPX.Return", "VIX.Return")])

# DCC coefficients
coef(fitDcc)
```

### Store Coefficients
```{r}
SPXcoef <- fitSPX@fit$coef
SPXsigma <- fitSPX@fit$sigma
SPXz <- fitSPX@fit$z
VIXcoef <- fitVIX@fit$coef
VIXsigma <- fitVIX@fit$sigma
VIXz <- fitVIX@fit$z   
DCCcoef <- fitDcc@mfit$coef
DCCQ <- fitDcc@mfit$Q
```

### Conditional Mean, Variance, and Correlation for the next date
{equations}
```{r}
# Conditional mean
SPXmean <- 0
VIXmean <- VIXcoef["mu"] + VIXcoef["ar1"] * returns[1000, "VIX.Return"]


# Conditional variance
SPXvariance <- SPXcoef["omega"] + SPXcoef["alpha1"] * returns[1000, "SPX.Return"]^2 + SPXcoef["beta1"] * SPXsigma[1000]^2
VIXvariance <- VIXcoef["omega"] + VIXcoef["alpha1"] * returns[1000, "VIX.Return"]^2 + VIXcoef["beta1"] * VIXsigma[1000]^2

# Conditional correlation
rhobar <- (1/1000) * SPXz %*% VIXz
q11 <- 1.0 + DCCcoef["[Joint]dcca1"] * (SPXz[1000]^2 - 1) + DCCcoef["[Joint]dccb1"] * (DCCQ[[1000]][1,1] - 1)
q22 <- 1.0 + DCCcoef["[Joint]dcca1"] * (VIXz[1000]^2 - 1) + DCCcoef["[Joint]dccb1"] * (DCCQ[[1000]][2,2] - 1)
q12 <- rhobar + DCCcoef["[Joint]dcca1"] * (SPXz[1000] * VIXz[1000] - rhobar) + DCCcoef["[Joint]dccb1"] * (DCCQ[[1000]][1,2] - rhobar)
rho <- q12 / sqrt(q11 * q22)

# Cleaner output
names(VIXmean) <- NULL
names(SPXvariance) <- NULL
names(VIXvariance) <- NULL
rho <- rho[1, 1]

# Output
SPXmean
VIXmean
SPXvariance
VIXvariance
rho
```

### Portfolio Expected Change, Variance, and Delta-Normal VaR (Value at Risk)
{equation}
```{r}
delta <- portfolioGreeks$Delta
vega <- portfolioGreeks$Vega

# Portfolio expected change
portExpectedChange <- vega * (indexData[idx_DATE, "VIX"] / 100) * VIXmean

# Portfolio Variance
portVariance <- delta^2 * indexData[idx_DATE, "SPX"]^2 * SPXvariance + vega^2 * (indexData[idx_DATE, "VIX"] / 100)^2 * VIXvariance + delta * vega * indexData[idx_DATE, "SPX"] * (indexData[idx_DATE, "VIX"] / 100) * rho * sqrt(SPXvariance * VIXvariance)

# Portfolio standard deviation
portSD <- sqrt(portVariance)

# Portfolio delta-normal VaR
DNVaR <- -1.645 * (portExpectedChange - portSD)
format(DNVaR, big.mark = ",")
```

## **Filtered Historical Simulation**
{equation}
accounts for fat tail, etc.

## **Filtered Historical Simulation VaR for 1-Day Holding Period**

### Portfolio Value on Evaluation Date
```{r}
X <- optionData$Strike.Price
Quantity <- optionData$Quantity
Multiplier <- optionData$Multiplier
sig <- optionData$Implied.volatility
t <- optionData$time_to_expiry_years
r <- optionData$Rate

# Portfolio value on 10/30/2020
initPortValue <- sum(Multiplier * Quantity * GBSOption(TypeFlag = "c", S = SPOT, X = X, Time = t, r = r, b = r - q, sigma = sig)@price)
format(initPortValue, big.mark = ",")
```

### Simulate Returns
Using parameter estimates from DCC model in previous section [DCC Estimates][Conditional Mean, Variance, and Correlation for the next date].
```{r}
SPX_simReturn <- SPXmean + sqrt(SPXvariance) * SPXz # Vector of 1000 simulated returns
VIX_simReturn <- VIXmean + sqrt(VIXvariance) * VIXz # Vector of 1000 simulated returns
```

### Returns Distribution
```{r}
# Returns distribution of SPX

# Create intervals (bins) from -15% to 15%
bins <- seq(-15.5, 15.5, 1)
bins <- c(-100, bins, 100) # Set upper and lower bounds

# Create interval (bin) labels
bin_label <- seq(-15, 15)
bin_label <- c("< -15", bin_label, "> 15") # Set upper and lower bounds
bin_label <- paste0(bin_label, "%") # Add % to labels

# Cut returns into intervals (data binning)
SPX_simReturn_Cut <- cut(SPX_simReturn * 100, breaks = bins, labels = bin_label)

# Plot returns distribution
data.frame(Return = SPX_simReturn_Cut) %>% # Make data frame for ggplot 
  ggplot(aes(x = Return, y = ..prop.., group = 1)) + 
  geom_bar(fill="navyblue") +
  ggtitle("Return Distribution of SPX (1-Day Horizon)") +
  xlab("Return") +
  ylab("Frequency")
```

```{r}
# Returns distribution of VIX

# Create intervals (bins) from -15% to 15%
bins <- seq(-15.5, 15.5, 1)
bins <- c(-100, bins, 100) # Set upper and lower bounds

# Create interval (bin) labels
bin_label <- seq(-15, 15)
bin_label <- c("< -15", bin_label, "> 15") # Set upper and lower bounds
bin_label <- paste0(bin_label, "%") # Add % to labels

# Cut returns into intervals (data binning)
VIX_simReturn_Cut <- cut(VIX_simReturn * 100, breaks = bins, labels = bin_label)

# Plot returns distribution
data.frame(Return = VIX_simReturn_Cut) %>% # Make data frame for ggplot 
  ggplot(aes(x = Return, y = ..prop.., group = 1)) + 
  geom_bar(fill="navyblue") +
  ggtitle("Return Distribution of VIX (1-Day Horizon)") +
  xlab("Return") +
  ylab("Frequency") +
  theme(axis.text.x = element_text(angle = 90))
```

### FHS Value at Risk for 1-Day Holding Period
```{r}
newTau <- t - 3/365
newPortValue <- rep(0, 1000)
PL <- rep(0, 1000)

for (i in 1:1000) {
  
  # Calculate new SPX spot value using simulated return of SPX
  newSpot <- SPOT * exp(SPX_simReturn[i])
  
  # Calculate new volatility using simulated return of VIX
  newSigma <- sig * exp(VIX_simReturn[i])
  
  # Store new portfolio value
  newPortValue[i] <- sum(Multiplier * Quantity * GBSOption(TypeFlag = "c", S = newSpot, X = X, Time = newTau, r = r, b = r - q, sigma = newSigma)@price)
  
  # Store profit and loss
  PL[i] <- newPortValue[i] - initPortValue
}

FHSVaR_1_day <- -quantile(PL, 0.05)
format(FHSVaR_1_day, big.mark = ",")
```


## **Filtered Historical Simulation VaR for 1-Month Holding Period**

### Simulate Returns for 21 Days (1 Month)
Using parameter estimates from DCC model in previous section [DCC Estimates][Conditional Mean, Variance, and Correlation for the next date].
```{r}
# Days
n_day <- 21

# Simulate variances
simVariance <- data.frame(SPX = rep(0, n_day),
                          VIX = rep(0, n_day))
# Simulate means
simMean <- data.frame(SPX = rep(0, n_day),
                      VIX = rep(0, n_day))
# 1,000 Z's (shocks)
Z <- data.frame(SPX = SPXz, 
                VIX = VIXz)
# Simulate returns
simReturn <- data.frame(SPX = rep(0, n_day),
                        VIX = rep(0, n_day))

# Set variances and means for Evaluation Date + 1
simVariance[1, "SPX"] <- SPXvariance
simVariance[1, "VIX"] <- VIXvariance
simMean[1, "SPX"] <- SPXmean
simMean[1, "VIX"] <- VIXmean
```

### Simulation
```{r}
set.seed(123)

# Vector used to hold 21-day returns
SPX_simReturn_21 <- rep(0, 5000)
VIX_simReturn_21 <- rep(0, 5000)

newTau <- t - 31/365
newPortValue <- rep(0, 5000)
PL <- rep(0, 5000)

for (i in 1:5000) {
  # Draw a sample of 21 shocks to use for 21 days
  shock <- Z[sample(1:1000, size = n_day, replace = TRUE), ]
  
  # Calculate simulated returns for Evaluation Date + 1
  simReturn[1, ] <- simMean[1, ] + sqrt(simVariance[1, ]) * shock[1, ]
  
  for (j in 2:n_day) {
    # Update VIX mean return
    simMean[j, "VIX"] <- VIXcoef["mu"] + VIXcoef["ar1"] * simReturn[j - 1, "VIX"]
    
    # Update variances
    simVariance[j, "SPX"] <- SPXcoef["omega"] + SPXcoef["alpha1"] * simReturn[j - 1, "SPX"]^2 + SPXcoef["beta1"] * simVariance[j - 1, "SPX"]
    simVariance[j, "VIX"] <- VIXcoef["omega"] + VIXcoef["alpha1"] * simReturn[j - 1, "VIX"]^2 + VIXcoef["beta1"] * simVariance[j - 1, "VIX"]
    
    # Calculate returns
    simReturn[j, ] <- simMean[j, ] + sqrt(simVariance[j, ]) * shock[j, ]
  }
  
  # Store simulated 21-day return
  SPX_simReturn_21[i] <- sum(simReturn$SPX)
  VIX_simReturn_21[i] <- sum(simReturn$VIX)
  
  # Simulate SPX and VIX values for 21 days
  newSpot <- SPOT * exp(SPX_simReturn_21[i])
  newSigma <- sig * exp(VIX_simReturn_21[i])
  
  # Calculate simulated portfolio value
  newPortValue[i] <- sum(Multiplier * Quantity * GBSOption(TypeFlag = "c", S = newSpot, X = X, Time = newTau, r = r, b = r - q, sigma = newSigma)@price)
  
  # Store profit and loss
  PL[i] <- newPortValue[i] - initPortValue
}

print(paste0("Number of Simulations: ", i))
```

### Returns Distribution
```{r}
# Returns distribution of SPX

# Create intervals (bins) from -15% to 15%
bins <- seq(-15.5, 15.5, 1)
bins <- c(-100, bins, 100) # Set upper and lower bounds

# Create interval (bin) labels
bin_label <- seq(-15, 15)
bin_label <- c("< -15", bin_label, "> 15") # Set upper and lower bounds
bin_label <- paste0(bin_label, "%") # Add % to labels

# Cut returns into intervals (data binning)
SPX_simReturn_21_Cut <- cut(SPX_simReturn_21 * 100, breaks = bins, labels = bin_label)

# Plot returns distribution
data.frame(Return = SPX_simReturn_21_Cut) %>% # Make data frame for ggplot 
  ggplot(aes(x = Return, y = ..prop.., group = 1)) + 
  geom_bar(fill="navyblue") +
  ggtitle("Return Distribution of SPX (21-Day Horizon)") +
  xlab("Return") +
  ylab("Frequency") +
  theme(axis.text.x = element_text(angle = 90))
```


```{r}
# Returns distribution of VIX

# Create intervals (bins) from -100% to 100%
increment <- 10
bins <- seq(-(100 + increment/2), 100 + increment/2, increment)
bins <- c(-500, bins, 500) # Set upper and lower bounds

# Create interval (bin) labels
bin_label <- seq(-100, 100, increment)
bin_label <- c("< -100", bin_label, "> 100") # Set upper and lower bounds
bin_label <- paste0(bin_label, "%") # Add % to labels

# Cut returns into intervals (data binning)
VIX_simReturn_21_Cut <- cut(VIX_simReturn_21 * 100, breaks = bins, labels = bin_label)

# Plot returns distribution
data.frame(Return = VIX_simReturn_21_Cut) %>% # Make data frame for ggplot 
  ggplot(aes(x = Return, y = ..prop.., group = 1)) + 
  geom_bar(fill="navyblue") +
  ggtitle("Return Distribution of VIX (21-Day Horizon)") +
  xlab("Return") +
  ylab("Frequency") +
  theme(axis.text.x = element_text(angle = 90))
```

### FHS Value at Risk for 1-Month Holding Period
```{r}
FHSVaR_21_day <- -quantile(PL, 0.05)
format(FHSVaR_21_day, big.mark = ",")
```

